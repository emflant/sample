{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b6eb9b-501c-49b9-af31-d522275c0367",
   "metadata": {},
   "source": [
    "### ì•½ê°„ì˜ í…ŒìŠ¤íŠ¸\n",
    "íŒŒë¼ë©”í„°ê°€ ë„ˆë¬´ í—·ê°ˆë ¤ì„œ, ê·¸ê±¸ í•œë²ˆ í…ŒìŠ¤íŠ¸í•´ë³´ë ¤í•¨ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ebab41-1e5c-40bf-9e51-590e8a3afd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975a6a5a-470c-4ff5-b8ef-1e05d7f96788",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"gemma2:9b\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://host.docker.internal:11434\"\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46b6314-7890-4313-886e-2c3a3eececb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"This is a bit of a trick question!  \\n\\nYou can't do standard math with apples.  ğŸ + ğŸ = ğŸğŸ, but not a number like 15. \\n\\n\\nLet me know if you want to try a different kind of problem! ğŸ˜Š \\n\", additional_kwargs={}, response_metadata={'model': 'gemma2:9b', 'created_at': '2024-10-10T13:11:32.772208Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 7660926584, 'load_duration': 61644834, 'prompt_eval_count': 19, 'prompt_eval_duration': 1200365000, 'eval_count': 60, 'eval_duration': 6397142000}, id='run-ee4da525-9e76-4727-a9f8-9f426f32ad00-0', usage_metadata={'input_tokens': 19, 'output_tokens': 60, 'total_tokens': 79})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What's 7 ğŸ 8?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a24da5d5-ac1d-4c2c-ad0a-a3911e9b08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"question\": \"2 ğŸ 4\", \"result\": \"8\"},\n",
    "    {\"question\": \"3 ğŸ 5\", \"result\": \"15\"},\n",
    "    {\"question\": \"7 ğŸ 3\", \"result\": \"21\"},\n",
    "    {\"question\": \"What did the cow say to the moon?\", \"result\": \"nothing at all\"},\n",
    "    {\n",
    "        \"question\": \"Write me a poem about the moon\",\n",
    "        \"result\": \"One for the moon, and one for me, who are we to talk about the moon?\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "122f8f04-43ad-48ea-bd5e-8d128a686458",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "embeddings = OllamaEmbeddings(model=\"gemma2:9b\", \n",
    "                             base_url=\"http://host.docker.internal:11434\")\n",
    "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)\n",
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore, k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d70ad6e-fddc-40bf-a17b-0098559e1b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Write me a poem about the moon',\n",
       "  'result': 'One for the moon, and one for me, who are we to talk about the moon?'},\n",
       " {'question': 'What did the cow say to the moon?', 'result': 'nothing at all'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({\"question\": \"moon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d6abaa-0910-4cc5-aa67-cb9b78f3ac78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': '3 ğŸ 5', 'result': '15'}, {'question': '7 ğŸ 3', 'result': '21'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({\"question\": \"203 ğŸ 302\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc9f4e2-a0f4-48b2-b1f7-9f49068bffec",
   "metadata": {},
   "source": [
    "í‚¤ê°’ì´ ìƒê´€ì´ ì—†ìŒ. abc ë¡œ í•˜ë˜ë§ë˜.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fbbc355-59a5-4a4e-8e45-74e2addbd698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Write me a poem about the moon',\n",
       "  'result': 'One for the moon, and one for me, who are we to talk about the moon?'},\n",
       " {'question': 'What did the cow say to the moon?', 'result': 'nothing at all'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({\"abc\": \"moon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47354a4e-763d-43a3-94a5-b13a3589de92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': '3 ğŸ 5', 'result': '15'}, {'question': '7 ğŸ 3', 'result': '21'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({\"abc\": \"203 ğŸ 302\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6dbfd-34d8-4397-932f-8e75a4cd10f6",
   "metadata": {},
   "source": [
    "### FewShotChatMessagePromptTemplate\n",
    "\n",
    "ìœ„ì— `examples` ë°ì´í„°ëŠ” `question`ê³¼ `result`ë¡œ ì´ë¤„ì§„ ë°ì´í„°ì¸ë°, ai ë¡œ ë°”ì¸ë”©í•  ë•Œ, ì˜ëª»ëœ \"output\"ìœ¼ë¡œ ë§¤í•‘í•˜ë©´ ì–´ë–¨ê¹Œ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b60fce-e06a-471e-a2a1-22559bb21e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{question}\"), (\"ai\", \"{output}\")]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e1c96-8223-4190-9a0a-75a5138f9549",
   "metadata": {},
   "source": [
    "ì•„ë˜ì²˜ëŸ¼ ì˜¤ë¥˜ê°€ ë‚œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f98d8e2-9ea1-4dab-b3a4-15772fb3b9f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfew_shot_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms 2 ğŸ 3000?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/prompts/base.py:193\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    192\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/runnables/base.py:1926\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1923\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1924\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1925\u001b[0m         Output,\n\u001b[0;32m-> 1926\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1929\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1930\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1934\u001b[0m     )\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1936\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/runnables/config.py:394\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    393\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/prompts/base.py:168\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m    167\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_inner_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/prompts/chat.py:773\u001b[0m, in \u001b[0;36mBaseChatPromptTemplate.format_prompt\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m    765\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt. Should return a PromptValue.\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m        PromptValue.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 773\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mmessages)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/langchain_core/prompts/few_shot.py:395\u001b[0m, in \u001b[0;36mFewShotChatMessagePromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# Get the examples to use.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_examples(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    394\u001b[0m examples \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 395\u001b[0m     {k: \u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexample_prompt\u001b[38;5;241m.\u001b[39minput_variables} \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples\n\u001b[1;32m    396\u001b[0m ]\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# Format the examples.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    399\u001b[0m     message\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m examples\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexample_prompt\u001b[38;5;241m.\u001b[39mformat_messages(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexample)\n\u001b[1;32m    402\u001b[0m ]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'output'"
     ]
    }
   ],
   "source": [
    "few_shot_prompt.invoke(input=\"What's 2 ğŸ 3000?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a1e31-a754-492b-8742-aec0b3e3da59",
   "metadata": {},
   "source": [
    "ì œëŒ€ë¡œ result ë¡œ ë°”ê¾¸ë„ë¡ í•œë‹¤. input_variables ëŠ” selector ì— ì¿¼ë¦¬ë¡œ ë³´ë‚´ëŠ” ê°’ì¸ ê±° ê°™ì€ë°, ë­ë¥¼ ê°€ì ¸ë‹¤ë†”ë„ ìƒê´€ì´ ì—†ìŒ.. ì´ìƒí•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d032897-8fae-42be-a28f-33d178f139e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{question}\"), (\"ai\", \"{result}\")]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d31f7124-4d09-4d31-93ef-71b061ec5e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='7 ğŸ 3', additional_kwargs={}, response_metadata={}), AIMessage(content='21', additional_kwargs={}, response_metadata={}), HumanMessage(content='3 ğŸ 5', additional_kwargs={}, response_metadata={}), AIMessage(content='15', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt.invoke(input=\"What's 2 ğŸ 3000?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0563aa6-d994-4cb5-9a6b-f8669972a61b",
   "metadata": {},
   "source": [
    "aaaaa ë¡œ í‚¤ê°’ì„ ë°”ê¾¸ë”ë¼ë„, ë²¡í„°ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ”ë° ë¬¸ì œê°€ ì—†ë‹¤. ë‹¤ë§Œ invoke ê°’ì— object í˜•ìœ¼ë¡œ ë„£ê²Œëœë‹¤ë©´ input_variables ì™€ ë§ì¶°ì•¼ í•œë‹¤. ì•ˆê·¸ëŸ¬ë©´ ì—ëŸ¬ ë°œìƒí•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ec9b499-0a55-4c3b-bb7e-8d521f901641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='7 ğŸ 3', additional_kwargs={}, response_metadata={}), AIMessage(content='21', additional_kwargs={}, response_metadata={}), HumanMessage(content='3 ğŸ 5', additional_kwargs={}, response_metadata={}), AIMessage(content='15', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"aaaaa\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{question}\"), (\"ai\", \"{result}\")]\n",
    "    )\n",
    ")\n",
    "few_shot_prompt.invoke(input={\"aaaaa\":\"What's 2 ğŸ 3000?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5aadd62-0dae-4205-b9f5-3b2cedf60317",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{question}\"), (\"ai\", \"{result}\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f4b4132-0e7a-4d97-8c55-4a856902e954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a wondrous wizard of math.', additional_kwargs={}, response_metadata={}), HumanMessage(content='3 ğŸ 5', additional_kwargs={}, response_metadata={}), AIMessage(content='15', additional_kwargs={}, response_metadata={}), HumanMessage(content='7 ğŸ 3', additional_kwargs={}, response_metadata={}), AIMessage(content='21', additional_kwargs={}, response_metadata={}), HumanMessage(content='30 ğŸ 5', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt.invoke(input={\"question\":\"30 ğŸ 5\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8bd18ae-7329-4b8d-b1f6-8e67f3c42c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = final_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84b14b1e-270e-4e11-a54c-63cdd02c2661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='56 ğŸ  \\n\\nRemember, \"ğŸ\" means multiplication! ğŸ˜Š  \\n', additional_kwargs={}, response_metadata={'model': 'gemma2:9b', 'created_at': '2024-10-10T13:12:36.723334Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 2530174666, 'load_duration': 57357583, 'prompt_eval_count': 62, 'prompt_eval_duration': 646020000, 'eval_count': 18, 'eval_duration': 1819768000}, id='run-064e0160-7a33-4533-ad2b-1eb89419f0a9-0', usage_metadata={'input_tokens': 62, 'output_tokens': 18, 'total_tokens': 80})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What's 7 ğŸ 8?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec515650-70f9-467d-9b5d-9ab09276b06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
