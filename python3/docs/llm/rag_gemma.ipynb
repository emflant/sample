{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a78075f-b86b-4394-92be-67d15ec768fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain_core : 0.3.10\n",
      "langchain_ollama : 0.2.0\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "import langchain_core, langchain_ollama\n",
    "import pprint\n",
    "\n",
    "#langchain_core : 0.3.10\n",
    "#langchain_ollama : 0.2.0\n",
    "print(\"langchain_core : \" + langchain_core.__version__)\n",
    "print(\"langchain_ollama : \" + langchain_ollama.__version__)\n",
    "\n",
    "# model=\"llama3.2:3b\" 에서 했으나, tool calling 이 제대로 적용되지 않음.\n",
    "# 버전은 낮지만, 더 큰 모델을 사용했더니 성공. llama3.1:8b\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma2:2b\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://host.docker.internal:11434\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c093129a-0a1f-48ef-b48a-f166d3e9940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5209"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"container\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://sourcebox.dev/blog/20241014/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192d7d4c-393a-47fb-aa15-4725375d96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=100, \n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f443e744-5d2e-487e-a00f-1bc2d4e3a45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06460a5c-8720-43dd-8ef7-86951ccd75c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b6d821d-9c0a-40cc-8841-5aaaa02d3b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=OllamaEmbeddings(\n",
    "        model=\"gemma2:2b\",\n",
    "        base_url=\"http://host.docker.internal:11434\"\n",
    "    )\n",
    ")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "154f5898-43b5-4fd8-85c2-972d236309f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f748c769-b2d6-468c-b2fd-2b67a8ac8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\n",
    "    \"Tool Calling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aeb1883f-e531-417a-965e-fb663f1bc25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb9f0ecf-e7e2-40b9-97ed-55ddbb001080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='#langchain_core : 0.3.10\n",
      "#langchain_ollama : 0.2.0\n",
      "print(\"langchain_core : \" + langchain_core.__version__)\n",
      "print(\"langchain_ollama : \" + langchain_ollama.__version__)\n",
      "AI 모델로 llama3.1:8b 버전을 선택했다. 원래는 3b 모델을 사용해보려 했으나, 툴 호출 기능이 제대로 작동하지 않아, 8b모델로 했더니 결과가 만족스러웠다. 참고로 gemma2 는 tool calling 기능이 없었다.\n",
      "from langchain_ollama import ChatOllama\n",
      "\n",
      "llm = ChatOllama(\n",
      "    model=\"llama3.1:8b\",\n",
      "    temperature=0,\n",
      "    base_url=\"http://host.docker.internal:11434\"\n",
      ")\n",
      "기본적인 수학 계산을 AI에게 요청해 봤다.\n",
      "ai_msg = llm.invoke(input=\"What is 3 * 12? Also, what is 11 + 49?\")\n",
      "이정도 질의는 별다른 셋팅이 없어도 정확하게 잘 나온다. tool-calling 기능이 필요하지 않은 수준이다.\n",
      "print(ai_msg.content)\n",
      "\n",
      "\"\"\"\n",
      "Two simple math questions!\n",
      "\n",
      "**1. 3 * 12 = 36**\n",
      "\n",
      "Multiplying 3 by 12 gives us a product of 36.\n",
      "\n",
      "**2. 11 + 49 = 60**' metadata={'source': 'https://sourcebox.dev/blog/20241014/', 'start_index': 729}\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6c511-8ba6-4df8-9c9a-4b4f4d2e148f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
