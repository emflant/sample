{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17847a0d-b7a8-4e1f-9aa3-8a0dd0b16df4",
   "metadata": {},
   "source": [
    "### How to use few shot examples in chat models\n",
    "https://python.langchain.com/docs/how_to/few_shot_examples_chat/\n",
    "\n",
    "질문과 답변의 쌍을 여러개 예시로 만들어, 질의할 때 같이 포함하여 답변의 정확도를 크게 끌어올린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a8da3c-0d20-40c9-87c4-b9536772a03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain_core : 0.3.9\n",
      "langchain_ollama : 0.2.0\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "import langchain_core, langchain_ollama\n",
    "\n",
    "#langchain_core : 0.3.9\n",
    "#langchain_ollama : 0.2.0\n",
    "print(\"langchain_core : \" + langchain_core.__version__)\n",
    "print(\"langchain_ollama : \" + langchain_ollama.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea284657-d3bd-4ea7-b20a-8a34817c2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"gemma2:9b\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://host.docker.internal:11434\"\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1fd96a1-8522-4aaf-87ff-eef89bf994e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain1 = first_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ad0d7b-39fb-4dd2-a9a9-d71c7a7d2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg1 = chain1.invoke({\"input\": \"What is 8 🍎 9?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbe82f88-5e56-4dc1-9510-3a8ab0b64f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, a delightful riddle!  \\n\\nIn the realm of numbers, \"🍎\" usually means addition. So, 8 🍎 9 is simply:\\n\\n8 + 9 = 17 \\n\\n\\nLet me know if you have any other magical mathematical puzzles for me! ✨🧮✨'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg1.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a89dd36-8895-4156-b980-466bc27dcaae",
   "metadata": {},
   "source": [
    "### How to use few shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661fa90c-725d-4012-8f45-701629fbc4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"2 🍎 4\", \"output\": \"8\"},\n",
    "    {\"input\": \"3 🍎 5\", \"output\": \"15\"},\n",
    "    {\"input\": \"7 🍎 3\", \"output\": \"21\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66df84ca-27a2-49ae-928c-b2891d14315d",
   "metadata": {},
   "source": [
    "프롬프트 템플릿을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0c672e3-bd18-41b1-9956-77c88e9b0f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69803a1d-1a03-4255-9186-1caa359c3ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb172aa-9cf8-4bea-a19e-598fc38a410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotChatMessagePromptTemplate(examples=[{'input': '2 🍎 4', 'output': '8'}, {'input': '3 🍎 5', 'output': '15'}, {'input': '7 🍎 3', 'output': '21'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75277360-b3dc-4943-85db-bcd330629619",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79b91104-21ab-454b-a658-a0fffd643ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = final_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0f7d545-7a4a-462f-875d-27c8cb7b85d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg2 = chain2.invoke({\"input\": \"What is 8 🍎 9?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcf249c4-3a10-45e7-bbe0-9880d1a4bd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='72 \\n\\nRemember, \"🍎\" means multiplication!  😊  \\n', additional_kwargs={}, response_metadata={'model': 'gemma2:9b', 'created_at': '2024-10-10T23:58:43.416877Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 6294954000, 'load_duration': 3631200750, 'prompt_eval_count': 77, 'prompt_eval_duration': 923750000, 'eval_count': 17, 'eval_duration': 1733492000}, id='run-60626c5b-5f56-4159-a2b3-5c81c7e2b28f-0', usage_metadata={'input_tokens': 77, 'output_tokens': 17, 'total_tokens': 94})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3fe031-1588-442c-921a-2e3710f271ae",
   "metadata": {},
   "source": [
    "### Dynamic few-shot prompting\n",
    "\n",
    "여러가지 질의-답변 쌍중에 관련있는 예제만 k 개 추출하여 모델에 넣어 답변의 정확도를 높이는 방법.\n",
    "여기서는 Chroma 벡터DB로 검색."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "131bc7ed-a45d-4666-9c0c-e659359ae57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fc3154f9-1444-4430-b09b-b94456b26470",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"gemma2:9b\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://host.docker.internal:11434\"\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "93eb8a52-6ae2-4cfc-b756-22a4a10d5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"2 🍎 4\", \"output\": \"8\"},\n",
    "    {\"input\": \"3 🍎 5\", \"output\": \"15\"},\n",
    "    {\"input\": \"7 🍎 3\", \"output\": \"21\"},\n",
    "    {\"input\": \"What did the cow say to the moon?\", \"output\": \"nothing at all\"},\n",
    "    {\n",
    "        \"input\": \"Write me a poem about the moon\",\n",
    "        \"output\": \"One for the moon, and one for me, who are we to talk about the moon?\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6ed5f60a-4009-41fe-9cae-419c6cc050bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vectorize = [\" \".join(example.values()) for example in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "22ef1b0c-2549-4d98-becc-be142c8db40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 🍎 4 8',\n",
       " '3 🍎 5 15',\n",
       " '7 🍎 3 21',\n",
       " 'What did the cow say to the moon? nothing at all',\n",
       " 'Write me a poem about the moon One for the moon, and one for me, who are we to talk about the moon?']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fcaccd7c-f9d5-4589-aae6-a2cdf1d5467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"gemma2:9b\", \n",
    "                             base_url=\"http://host.docker.internal:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "566ccbdb-4797-4409-b22a-6fd90ebb1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "352b8322-6f3e-4c9a-b240-b340dab5ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore, k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fb19d16b-1cc4-40f7-a6a8-b90a621f56ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'Write me a poem about the moon',\n",
       "  'output': 'One for the moon, and one for me, who are we to talk about the moon?'},\n",
       " {'input': 'What did the cow say to the moon?', 'output': 'nothing at all'}]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({\"input\": \"horse\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc61769-b680-4488-9062-4ec86254378b",
   "metadata": {},
   "source": [
    "3 🦜 3 이라는 인풋값을 넣으면 그에 맞는 예시를 추출하게 된다. 사실 수많은 예시중에 모델에 넣을 예시를 선택하는 것도 LLM 을 사용하게 될줄은 몰랐다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c20d5029-0faf-41fd-83e8-985e79183c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '3 🍎 5', 'output': '15'}, {'input': '7 🍎 3', 'output': '21'}]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({\"input\": \"3 🦜 3\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1db77-3ace-4766-91b0-a9bf28d9c3ee",
   "metadata": {},
   "source": [
    "### Create prompt template\n",
    "\n",
    "이제 실제 질의할 프롬프트를 만들어 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e7b40825-893d-4cbe-98f2-42c5be0a779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "af5d6725-f41a-4c1c-b16f-1096f766a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "134e5235-0c0d-4c5e-91b1-07bc4d10e7b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotChatMessagePromptTemplate(example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain_chroma.vectorstores.Chroma object at 0xffff545e0ad0>, k=2, example_keys=None, input_keys=None, vectorstore_kwargs=None), input_variables=['input2'], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b91ed093-24f4-445c-88cb-2c8d0505a221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='3 🍎 5', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='15', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='7 🍎 3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='21', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt.invoke(input=\"What's 3 🍎 10?\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "904de8aa-6126-4978-adae-24642876fa24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Write me a poem about the moon', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='One for the moon, and one for me, who are we to talk about the moon?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What did the cow say to the moon?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nothing at all', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt.invoke(input={\"input\":\"horse\"}).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7202f7bf-057b-45a4-a076-f489a2612fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "000df3bb-fe6c-4f11-b268-17858a30ae11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='600  \\n\\nRemember, \"🍎\" means multiplication! 😊  \\n', additional_kwargs={}, response_metadata={'model': 'gemma2:9b', 'created_at': '2024-10-09T13:27:47.397424Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 2420239250, 'load_duration': 57965875, 'prompt_eval_count': 64, 'prompt_eval_duration': 646250000, 'eval_count': 17, 'eval_duration': 1709808000}, id='run-d2dc83d1-98ea-44c3-af60-efe1569c963f-0', usage_metadata={'input_tokens': 64, 'output_tokens': 17, 'total_tokens': 81})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What's 20 🍎 30?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3af9ed-d5fe-47f2-82b4-a5548ae27aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
