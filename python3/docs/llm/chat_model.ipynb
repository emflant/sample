{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17847a0d-b7a8-4e1f-9aa3-8a0dd0b16df4",
   "metadata": {},
   "source": [
    "### How to use few shot examples in chat models\n",
    "https://python.langchain.com/docs/how_to/few_shot_examples_chat/\n",
    "\n",
    "질문과 답변의 쌍을 여러개 예시로 만들어, 질의할 때 같이 포함하여 답변의 정확도를 크게 끌어올린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a8da3c-0d20-40c9-87c4-b9536772a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea284657-d3bd-4ea7-b20a-8a34817c2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"gemma2:9b\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://host.docker.internal:11434\"\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ad0d7b-39fb-4dd2-a9a9-d71c7a7d2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = llm.invoke(\"What is 2 🍎 9?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe82f88-5e56-4dc1-9510-3a8ab0b64f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This looks like a fun math problem with a twist!  \\n\\nSince we're dealing with apples, it's likely not standard addition. Here are a couple of ways to think about it:\\n\\n* **Counting Apples:** If you have 2 apples and then add 9 more, you would have a total of 11 apples. So, 2 🍎 9 = 11 🍎\\n\\nLet me know if you had something else in mind!  \\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661fa90c-725d-4012-8f45-701629fbc4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"2 🍎 2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2 🍎 3\", \"output\": \"5\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c672e3-bd18-41b1-9956-77c88e9b0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69803a1d-1a03-4255-9186-1caa359c3ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb172aa-9cf8-4bea-a19e-598fc38a410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotChatMessagePromptTemplate(examples=[{'input': '2 🍎 2', 'output': '4'}, {'input': '2 🍎 3', 'output': '5'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75277360-b3dc-4943-85db-bcd330629619",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab8f6492-9db3-4880-b6fd-2ac17183cfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a wondrous wizard of math.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '2 🍎 2', 'output': '4'}, {'input': '2 🍎 3', 'output': '5'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79b91104-21ab-454b-a658-a0fffd643ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = final_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f7d545-7a4a-462f-875d-27c8cb7b85d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg2 = chain.invoke({\"input\": \"What is 9 🍎 2?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcf249c4-3a10-45e7-bbe0-9880d1a4bd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 🍎 2 = 11 \\n\\nRemember, when we use \"🍎\" it means we\\'re adding the numbers together!  😊  \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg2.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3fe031-1588-442c-921a-2e3710f271ae",
   "metadata": {},
   "source": [
    "### Dynamic few-shot prompting\n",
    "\n",
    "여러가지 질의-답변 쌍중에 관련있는 예제만 k 개 추출하여 모델에 넣어 답변의 정확도를 높이는 방법."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca75054e-f89b-4341-9f4a-84d1b3bea26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8980128-e7ca-499c-a06d-29f25f41f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3154f9-1444-4430-b09b-b94456b26470",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"gemma2:9b\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://host.docker.internal:11434\"\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93eb8a52-6ae2-4cfc-b756-22a4a10d5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"2 🦜 2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2 🦜 3\", \"output\": \"5\"},\n",
    "    {\"input\": \"2 🦜 4\", \"output\": \"6\"},\n",
    "    {\"input\": \"What did the cow say to the moon?\", \"output\": \"nothing at all\"},\n",
    "    {\n",
    "        \"input\": \"Write me a poem about the moon\",\n",
    "        \"output\": \"One for the moon, and one for me, who are we to talk about the moon?\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed5f60a-4009-41fe-9cae-419c6cc050bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vectorize = [\" \".join(example.values()) for example in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ef1b0c-2549-4d98-becc-be142c8db40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 🦜 2 4',\n",
       " '2 🦜 3 5',\n",
       " '2 🦜 4 6',\n",
       " 'What did the cow say to the moon? nothing at all',\n",
       " 'Write me a poem about the moon One for the moon, and one for me, who are we to talk about the moon?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcaccd7c-f9d5-4589-aae6-a2cdf1d5467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"gemma2:9b\", \n",
    "                             base_url=\"http://host.docker.internal:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566ccbdb-4797-4409-b22a-6fd90ebb1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739fbc17-b36d-4b5a-b662-89e771954435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "352b8322-6f3e-4c9a-b240-b340dab5ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore, k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb19d16b-1cc4-40f7-a6a8-b90a621f56ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'Write me a poem about the moon',\n",
       "  'output': 'One for the moon, and one for me, who are we to talk about the moon?'},\n",
       " {'input': 'What did the cow say to the moon?', 'output': 'nothing at all'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({\"input\": \"horse\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc61769-b680-4488-9062-4ec86254378b",
   "metadata": {},
   "source": [
    "3 🦜 3 이라는 인풋값을 넣으면 그에 맞는 예시를 추출하게 된다. 사실 수많은 예시중에 모델에 넣을 예시를 선택하는 것도 LLM 을 사용하게 될줄은 몰랐다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c20d5029-0faf-41fd-83e8-985e79183c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '2 🦜 2', 'output': '4'}, {'input': '2 🦜 3', 'output': '5'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({\"input\": \"3 🦜 3\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1db77-3ace-4766-91b0-a9bf28d9c3ee",
   "metadata": {},
   "source": [
    "### Create prompt template\n",
    "\n",
    "이제 실제 질의할 프롬프트를 만들어 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7b40825-893d-4cbe-98f2-42c5be0a779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af5d6725-f41a-4c1c-b16f-1096f766a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b91ed093-24f4-445c-88cb-2c8d0505a221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='2 🦜 4', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='6', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='2 🦜 3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='5', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt.invoke(input=\"What's 3 🦜 10?\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7202f7bf-057b-45a4-a076-f489a2612fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01b13418-b81e-493c-9d7e-4daa70e27a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a wondrous wizard of math.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='2 🦜 4', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='6', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='2 🦜 3', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='5', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's 3 🦜 13?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt.invoke(input=\"What's 3 🦜 13?\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f16e4e91-a237-460b-8d15-292a1aabe8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = final_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be16e79f-6d32-4d7e-ab97-55230892630e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='This looks like a fun code!  \\n\\n\"🦜\" seems to mean \"plus\". So, 3 🦜 13 is the same as 3 + 13 = 16. \\n\\n\\nLet me know if you have more math puzzles for me! 😊 \\n', additional_kwargs={}, response_metadata={'model': 'gemma2:9b', 'created_at': '2024-10-08T15:12:49.509617Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 6663140500, 'load_duration': 54041667, 'prompt_eval_count': 61, 'prompt_eval_duration': 110685000, 'eval_count': 60, 'eval_duration': 6490037000}, id='run-1d5e1324-f82a-456d-a28c-1ea7c25eb159-0', usage_metadata={'input_tokens': 61, 'output_tokens': 60, 'total_tokens': 121})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What's 3 🦜 13?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000df3bb-fe6c-4f11-b268-17858a30ae11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
