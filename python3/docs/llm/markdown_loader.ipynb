{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0b0bf8-0d24-4b5a-85d0-535cc7630678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "markdown_path = \"./data/blog.md\"\n",
    "loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "612804c3-ea76-43b7-98b8-b0ee88d8bfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884c194c-6117-4c8d-8a3c-cd1a5bd200fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(data[0], Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efa32e60-88c7-4872-a10c-29c69adb8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2 = UnstructuredMarkdownLoader(markdown_path, mode=\"elements\")\n",
    "data2 = loader2.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f768ac82-7649-4766-acde-7674cab1cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of documents: 26\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numer of documents: {len(data2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98568b1a-6316-4b0f-b910-4ae20c02d80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/blog.md', 'languages': ['eng'], 'file_directory': './data', 'filename': 'blog.md', 'filetype': 'text/markdown', 'last_modified': '2024-10-11T13:12:42', 'category': 'UncategorizedText', 'element_id': 'b9072d78481097d79902af69a803aedb'}, page_content='+++ title = \\'AI 모델 정확도 높이기: Langchain과 Few-shot 학습으로 모델 개선하기\\' date = 2024-10-11T12:37:48+09:00 draft = false tags = [\"ollama\", \"ai\", \"gemma\", \"langchain\"] +++'),\n",
       " Document(metadata={'source': './data/blog.md', 'languages': ['eng'], 'file_directory': './data', 'filename': 'blog.md', 'filetype': 'text/markdown', 'last_modified': '2024-10-11T13:12:42', 'category': 'NarrativeText', 'element_id': '8dabfee48778daf466b0cfdb3a521fe6'}, page_content='ChatGPT 같은 대형 언어 모델들도 특정 상황에서는 추가적인 학습 데이터가 필요할 때가 있는데, 이를 해결하기 위한 방법이 few-shot 학습이다. Few-shot 학습은 적은 수의 예시만으로도 모델이 새로운 문제에 잘 적응할 수 있게 도와주는 기술이다. 이 글에서는 Python의 Langchain 라이브러리를 사용하여, few-shot 학습을 AI 채팅 모델에 적용하고, 모델의 성능을 높이는 과정을 정리해본다. 같은 질문을 했을때, few-shot 학습전과 후의 AI모델 응답을 비교했는데 의도한대로 잘 나와서 놀랐다.'),\n",
       " Document(metadata={'source': './data/blog.md', 'languages': ['eng'], 'file_directory': './data', 'filename': 'blog.md', 'filetype': 'text/markdown', 'last_modified': '2024-10-11T13:12:42', 'category': 'UncategorizedText', 'element_id': '11154924448bdfbff2756fd936e3c96e'}, page_content='{{'),\n",
       " Document(metadata={'source': './data/blog.md', 'category_depth': 2, 'languages': ['eng'], 'file_directory': './data', 'filename': 'blog.md', 'filetype': 'text/markdown', 'last_modified': '2024-10-11T13:12:42', 'category': 'Title', 'element_id': 'ef914f83395f567650f234f7f71c1e8a'}, page_content='Few-shot 학습을 하지 않았을 때,'),\n",
       " Document(metadata={'source': './data/blog.md', 'languages': ['eng'], 'file_directory': './data', 'filename': 'blog.md', 'filetype': 'text/markdown', 'last_modified': '2024-10-11T13:12:42', 'parent_id': 'ef914f83395f567650f234f7f71c1e8a', 'category': 'NarrativeText', 'element_id': '1e02123d5b677b4b485c8470d2fba05c'}, page_content='Few-shot 학습하지 않았을때, 어떤 결과가 나오는지 우선 살펴보기로 한다. 먼저 오늘 실행에 필요한 라이브러리를 정의한다.'),\n",
       " Document(metadata={'source': './data/blog.md', 'category_depth': 1, 'languages': ['eng'], 'file_directory': './data', 'filename': 'blog.md', 'filetype': 'text/markdown', 'last_modified': '2024-10-11T13:12:42', 'parent_id': 'ef914f83395f567650f234f7f71c1e8a', 'category': 'ListItem', 'element_id': '56fa95e42bdcac10eafd9911f17118d6'}, page_content='ChatOllama: Ollama 모델을 사용한 채팅 인터페이스.'),\n",
       " Document(metadata={'source': './data/blog.md', 'category_depth': 1, 'languages': ['eng'], 'file_directory': './data', 'filename': 'blog.md', 'filetype': 'text/markdown', 'last_modified': '2024-10-11T13:12:42', 'parent_id': 'ef914f83395f567650f234f7f71c1e8a', 'category': 'ListItem', 'element_id': '7623b4a85cfdae39d5419e4a368695a3'}, page_content='ChatPromptTemplate: 프롬프트를 구성하기 위한 템플릿 생성.'),\n",
       " Document(metadata={'source': './data/blog.md', 'category_depth': 1, 'languages': ['eng'], 'file_directory': './data', 'filename': 'blog.md', 'filetype': 'text/markdown', 'last_modified': '2024-10-11T13:12:42', 'parent_id': 'ef914f83395f567650f234f7f71c1e8a', 'category': 'ListItem', 'element_id': '259a285a2d366663c64028778e6ca078'}, page_content='FewShotChatMessagePromptTemplate: few-shot 학습을 위한 프롬프트 템플릿.'),\n",
       " Document(metadata={'source': './data/blog.md', 'category_depth': 0, 'languages': ['eng'], 'file_directory': './data', 'filename': 'blog.md', 'filetype': 'text/markdown', 'last_modified': '2024-10-11T13:12:42', 'category': 'Title', 'element_id': '30e3dae3db9d3c3952f19698a4526258'}, page_content='python from langchain_ollama import ChatOllama from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate'),\n",
       " Document(metadata={'source': './data/blog.md', 'emphasized_text_contents': ['version', 'version'], 'emphasized_text_tags': ['b', 'b'], 'languages': ['eng'], 'file_directory': './data', 'filename': 'blog.md', 'filetype': 'text/markdown', 'last_modified': '2024-10-11T13:12:42', 'parent_id': '30e3dae3db9d3c3952f19698a4526258', 'category': 'NarrativeText', 'element_id': 'd12f5d9b817488851391cb4f687075f2'}, page_content='참고로 이 포스팅에서 사용한 langchain 라이브러리 버전은 아래와 같다. ```python import langchain_core, langchain_ollama print(\"langchain_core : \" + langchain_core.version) print(\"langchain_ollama : \" + langchain_ollama.version)')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae607a0-ef41-4f57-a71e-8ff80cc3b527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
