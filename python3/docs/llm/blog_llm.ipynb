{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493ab9fd-b80e-46b0-a0d6-614d8f686c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain_core : 0.3.10\n",
      "langchain_ollama : 0.2.0\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "import langchain_core, langchain_ollama\n",
    "\n",
    "#langchain_core : 0.3.10\n",
    "#langchain_ollama : 0.2.0\n",
    "print(\"langchain_core : \" + langchain_core.__version__)\n",
    "print(\"langchain_ollama : \" + langchain_ollama.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51abe1ce-0ed7-4362-8064-7a74bace71c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"gemma2:2b\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://host.docker.internal:11434\"\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99b9ce64-7d6d-4664-acf4-ed2eb51fa0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are a blogger who writes blog posts about programming. \n",
    "You need to read each block of program code and explain it in detail. \n",
    "The explanation should be professional and knowledgeable like a programming blogger, \n",
    "and written in Korean.\"\"\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain1 = first_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab5e962a-c235-4d4c-b129-179230e7d851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Python LangChain: ChatOllama를 활용한 대화형 AI 모델 구축 및 사용\n",
      "\n",
      "이 글에서는 Python에서 Langchain 라이브러리를 활용하여 **ChatOllama**를 이용한 대화형 AI 모델을 구축하고, 그 작동 방식에 대해 자세히 설명합니다. \n",
      "\n",
      "### 1. 필요한 라이브러리 임포트\n",
      "\n",
      "```python\n",
      "from langchain_ollama import ChatOllama\n",
      "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
      "```\n",
      "\n",
      "이 부분에서는 Langchain의 `ChatOllama` 클래스를 사용하여 **ChatOllama** 모델을 로드합니다. 또한, `langchain_core`와 `langchain_ollama` 라이브러리를 통해 필요한 기능들을 활용할 수 있습니다. \n",
      "\n",
      "\n",
      "### 2. 모델 및 버전 확인\n",
      "\n",
      "```python\n",
      "import langchain_core, langchain_ollama\n",
      "print(\"langchain_core : \" + langchain_core.__version__)\n",
      "print(\"langchain_ollama : \" + langchain_ollama.__version__)\n",
      "```\n",
      "\n",
      "이 부분에서는 `langchain_core`와 `langchain_ollama` 라이브러리의 버전을 확인합니다. \n",
      "\n",
      "\n",
      "### 3. ChatOllama 모델 초기화\n",
      "\n",
      "```python\n",
      "llm = ChatOllama(\n",
      "    model=\"gemma2:9b\",\n",
      "    temperature=0,\n",
      "    base_url=\"http://host.docker.internal:11434\"\n",
      ")\n",
      "```\n",
      "\n",
      "이 부분에서는 **ChatOllama** 모델을 초기화합니다. \n",
      "* `model`: \"gemma2:9b\"는  Gemma 2 모델을 사용하는 것을 의미합니다. \n",
      "* `temperature`: 0은 모델의 생성 가능성을 최소화하여 정확한 답변을 제공합니다. \n",
      "* `base_url`:  API 호출에 필요한 URL입니다.\n",
      "\n",
      "\n",
      "### 4. Prompt Template 활용\n",
      "\n",
      "```python\n",
      "first_prompt = ChatPromptTemplate.from_messages(\n",
      "    [\n",
      "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
      "        (\"human\", \"{input}\")\n",
      "    ]\n",
      ")\n",
      "```\n",
      "\n",
      "이 부분에서는 **ChatPromptTemplate**를 사용하여  \"system\"과 \"human\"의 답변을 포함한 Prompt Template를 생성합니다.\n",
      "\n",
      "\n",
      "### 5. AI 메시지 생성\n",
      "\n",
      "```python\n",
      "chain1 = first_prompt | llm\n",
      "ai_msg1 = chain1.invoke({\"input\": \"What is 8 🍎 9?\"})\n",
      "```\n",
      "\n",
      "이 부분에서는  `ChatPromptTemplate`와 `llm`를 결합하여 **AI 메시지**를 생성합니다.\n",
      "\n",
      "\n",
      "### 6. AI 메시지 출력 및 분석\n",
      "\n",
      "```python\n",
      "ai_msg1.content\n",
      "\n",
      "# 출력결과\n",
      "'Ah, a delightful riddle!  \n",
      "\n",
      "In the realm of numbers, \"🍎\" usually means addition. So, 8 🍎 9 is simply:\n",
      "\n",
      "8 + 9 = 17 \n",
      "\n",
      "\n",
      "Let me know if you have any other magical mathematical puzzles for me! ✨🧮✨'\n",
      "```\n",
      "\n",
      "이 부분에서는 생성된 AI 메시지의 내용을 출력합니다.  **AI 메시지**는 \"system\"과 \"human\"의 답변을 포함하여, 사용자의 질문에 대한 정확한 답변을 제공합니다.\n",
      "\n",
      "\n",
      "### 7. 예제 데이터 활용\n",
      "\n",
      "```python\n",
      "examples = [\n",
      "    {\"input\": \"2 🍎 4\", \"output\": \"8\"},\n",
      "    {\"input\": \"3 🍎 5\", \"output\": \"15\"},\n",
      "    {\"input\": \"7 🍎 3\", \"output\": \"21\"}\n",
      "]\n",
      "```\n",
      "\n",
      "이 부분에서는 **예제 데이터**를 사용하여  AI 모델을 학습시킵니다.\n",
      "\n",
      "\n",
      "### 8. Prompt Template 활용\n",
      "\n",
      "```python\n",
      "example_prompt = ChatPromptTemplate.from_messages(\n",
      "    [\n",
      "        (\"human\", \"{input}\"),\n",
      "        (\"ai\", \"{output}\")\n",
      "    ]\n",
      ")\n",
      "```\n",
      "\n",
      "이 부분에서는 **ChatPromptTemplate**를 사용하여  \"human\"과 \"ai\"의 답변을 포함한 Prompt Template를 생성합니다.\n",
      "\n",
      "\n",
      "### 9. Few-shot Prompt 활용\n",
      "\n",
      "```python\n",
      "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
      "    example_prompt=example_prompt,\n",
      "    examples=examples\n",
      ")\n",
      "```\n",
      "\n",
      "이 부분에서는 **Few-shot Prompt**를 사용하여  AI 모델을 학습시킵니다.\n",
      "\n",
      "\n",
      "### 10. 최종 Prompt Template 활용\n",
      "\n",
      "```python\n",
      "final_prompt = ChatPromptTemplate.from_messages(\n",
      "    [\n",
      "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
      "        few_shot_prompt,\n",
      "        (\"human\", \"{input}\")\n",
      "    ]\n",
      ")\n",
      "```\n",
      "\n",
      "이 부분에서는  **ChatPromptTemplate**를 사용하여  AI 모델을 학습시킵니다.\n",
      "\n",
      "\n",
      "### 11. AI 메시지 생성 및 출력\n",
      "\n",
      "```python\n",
      "chain2 = final_prompt | llm\n",
      "ai_msg2 = chain2.invoke({\"input\": \"What is 8 🍎 9?\"})\n",
      "```\n",
      "\n",
      "이 부분에서는  **ChatPromptTemplate**와 `llm`를 결합하여 **AI 메시지**를 생성합니다.\n",
      "\n",
      "\n",
      "### 12. AI 메시지 출력 및 분석\n",
      "\n",
      "```python\n",
      "ai_msg2\n",
      "\n",
      "# 출력결과\n",
      "'72 \n",
      "\n",
      "Remember, \"🍎\" means multiplication!  😊  \n",
      "',\n",
      "```\n",
      "\n",
      "이 부분에서는 생성된 AI 메시지를 출력하고, **AI 메시지**의 내용을 분석합니다.\n",
      "\n",
      "\n",
      "### 결론\n",
      "\n",
      "본 블로그 글은 Langchain 라이브러리를 활용하여 ChatOllama를 사용한 대화형 AI 모델 구축 및 작동 방식에 대한 설명입니다.  Langchain 라이브러리는 Python에서 AI 모델 개발을 위한 강력한 도구이며, 이 글은 **ChatOllama** 모델의 활용 방법과 다양한 Prompt Template를 통해 AI 모델을 학습시키는 과정을 보여줍니다. \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ai_msg1 = chain1.invoke({\"input\": \"\"\"\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "import langchain_core, langchain_ollama\n",
    "print(\"langchain_core : \" + langchain_core.__version__)\n",
    "print(\"langchain_ollama : \" + langchain_ollama.__version__)\n",
    "\n",
    "# 출력결과 \n",
    "langchain_core : 0.3.9\n",
    "langchain_ollama : 0.2.0\n",
    "```\n",
    "\n",
    "```python\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma2:9b\",\n",
    "    temperature=0,\n",
    "    base_url=\"http://host.docker.internal:11434\"\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "first_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "chain1 = first_prompt | llm\n",
    "ai_msg1 = chain1.invoke({\"input\": \"What is 8 🍎 9?\"})\n",
    "```\n",
    "\n",
    "```python\n",
    "ai_msg1.content\n",
    "\n",
    "# 출력결과\n",
    "'Ah, a delightful riddle!  \\n\\nIn the realm of numbers, \"🍎\" usually means addition. So, 8 🍎 9 is simply:\\n\\n8 + 9 = 17 \\n\\n\\nLet me know if you have any other magical mathematical puzzles for me! ✨🧮✨'\n",
    "```\n",
    "\n",
    "```python\n",
    "examples = [\n",
    "    {\"input\": \"2 🍎 4\", \"output\": \"8\"},\n",
    "    {\"input\": \"3 🍎 5\", \"output\": \"15\"},\n",
    "    {\"input\": \"7 🍎 3\", \"output\": \"21\"}\n",
    "]\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "```python\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "```python\n",
    "chain2 = final_prompt | llm\n",
    "ai_msg2 = chain2.invoke({\"input\": \"What is 8 🍎 9?\"})\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "ai_msg2\n",
    "\n",
    "# 출력결과\n",
    "'72 \\n\\nRemember, \"🍎\" means multiplication!  😊  \\n',\n",
    "```\n",
    "\"\"\"})\n",
    "print(ai_msg1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e753ef-1a71-49ee-ab2a-bc68061c5944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
